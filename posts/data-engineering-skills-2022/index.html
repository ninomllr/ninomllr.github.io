<!doctype html><html lang=en dir=auto>
<head><meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge">
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=robots content="index, follow">
<title>Data Engineering Skills 2022 | Nino M√ºller Dataverse</title>
<meta name=keywords content>
<meta name=description content="One of my tasks at Substring is to always scout for technology trends to find out what technologies help our clients most to reach their target to become Data-driven. The tech field for fats engineers is huge and evolving fast.
I put together a short list of tech skills that I think data engineers in 2022 should master to give as much value to clients as possible. Obviously there is a load of so called soft skills needed as well.">
<meta name=author content>
<link rel=canonical href=https://ninomueller.com/posts/data-engineering-skills-2022/>
<link crossorigin=anonymous href=/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css integrity="sha256-yIlj/i15RiAA/Q+xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as=style>
<script defer crossorigin=anonymous src=/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://ninomueller.com/favicon.ico>
<link rel=icon type=image/png sizes=16x16 href=https://ninomueller.com/favicon-16x16.png>
<link rel=icon type=image/png sizes=32x32 href=https://ninomueller.com/favicon-32x32.png>
<link rel=apple-touch-icon href=https://ninomueller.com/apple-touch-icon.png>
<link rel=mask-icon href=https://ninomueller.com/safari-pinned-tab.svg>
<meta name=theme-color content="#2e2e33">
<meta name=msapplication-TileColor content="#2e2e33">
<meta name=generator content="Hugo 0.92.1">
<noscript>
<style>#theme-toggle,.top-link{display:none}</style>
<style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style>
</noscript><meta property="og:title" content="Data Engineering Skills 2022">
<meta property="og:description" content="One of my tasks at Substring is to always scout for technology trends to find out what technologies help our clients most to reach their target to become Data-driven. The tech field for fats engineers is huge and evolving fast.
I put together a short list of tech skills that I think data engineers in 2022 should master to give as much value to clients as possible. Obviously there is a load of so called soft skills needed as well.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ninomueller.com/posts/data-engineering-skills-2022/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2022-02-04T22:42:14+01:00">
<meta property="article:modified_time" content="2022-02-04T22:42:14+01:00">
<meta name=twitter:card content="summary">
<meta name=twitter:title content="Data Engineering Skills 2022">
<meta name=twitter:description content="One of my tasks at Substring is to always scout for technology trends to find out what technologies help our clients most to reach their target to become Data-driven. The tech field for fats engineers is huge and evolving fast.
I put together a short list of tech skills that I think data engineers in 2022 should master to give as much value to clients as possible. Obviously there is a load of so called soft skills needed as well.">
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://ninomueller.com/posts/"},{"@type":"ListItem","position":3,"name":"Data Engineering Skills 2022","item":"https://ninomueller.com/posts/data-engineering-skills-2022/"}]}</script>
<script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Data Engineering Skills 2022","name":"Data Engineering Skills 2022","description":"One of my tasks at Substring is to always scout for technology trends to find out what technologies help our clients most to reach their target to become Data-driven. The tech field for fats engineers is huge and evolving fast.\nI put together a short list of tech skills that I think data engineers in 2022 should master to give as much value to clients as possible. Obviously there is a load of so called soft skills needed as well.","keywords":[],"articleBody":"One of my tasks at Substring is to always scout for technology trends to find out what technologies help our clients most to reach their target to become Data-driven. The tech field for fats engineers is huge and evolving fast.\nI put together a short list of tech skills that I think data engineers in 2022 should master to give as much value to clients as possible. Obviously there is a load of so called soft skills needed as well. Maybe I will do a post about them as well in the future.\nüîπProgramming / Coding In the end a data engineer is a highly specialized software engineer. So learn the most important languages to interact with data and data pipelines. If you know python, bash and SQL you will get far already. If you ever encounter someone that tells you SQL is an old language or that it‚Äôs not useful anymore, just laugh and walk away ü§£\nSome important tools like Spark rely heavily on Java and Scala so it can be important that you know this too.\n Basics SQL: https://www.dataquest.io/blog/sql-basics/ Basics Python: https://www.python.org/about/gettingstarted/  üîπSQL databases Many systems rely on some sort of SQL based database. Invest some time in SQL based systems like Postgres, Azure SQL, Snowflake others.\nMany developers believe that nowadays everything is about NoSQL because ‚Äúit‚Äôs more scalable‚Äù or ‚Äúit‚Äôs the way to go with big data‚Äù. While this might be true, it is also quite difficult to handle transactions and consistency in data with systems like this. Not everything that starts cheaper and faster in the beginning stays like that in the long run. ü§î Most OLTP systems and transactional data systems should and will still use an RDBMS system, so prepare for this.\nüîπCloud \u0026 Kubernetes Learn the basics about K8s as you will need to use it a lot to run data pipelines. If you are a beginner just tinker aroune with minikube on your local computer. Later decide to learn about how to work with one of the big cloud providers AWS, Azure and GCP. I personally prefer Azure because they have a great integration of tools like Apache Databricks, MLFlow and other stuff that I need regularly.\nIn the end I would choose based on who your target clients are. Swiss SMEs work with Azure, because they are used to work with Microsoft and trust in Google and Amazon is lower. Startups use AWS because it is a bit cheaper for smaller workloads.\n Learn Kubernetes: https://kubernetes.io/docs/tutorials/kubernetes-basics/  üîπNoSQL If you get into the big data field, it‚Äôs necessary to learn about NoSQL databases. Now, there are multiple types of NoSQL databases, some of them are highly available and some of them are highly consistent. Some are column-based, some are document-based and some are graph-based.\nI recommend to try and learn about a couple of them:\n MongoDB (https://www.mongodb.com/) Cassandra (https://cassandra.apache.org/_/index.html) ElasticSearch (https://www.elastic.co/) Azure Cosmos DB (https://azure.microsoft.com/en-us/services/cosmos-db/#overview) neo4j (https://neo4j.com/)  Just run them locally on your docker and tinker around. You can find a couple of docker files for them here https://github.com/irbigdata/data-dockerfiles\nüîπData Warehousing Learn about data warehouses and how to store data in them and systems of storing data like Kimball, Data Vault 2.0 or others. Learn about slowly changing dimensions, ELT, ETL and other concepts around DWHs.\n Data Vault 2.0: https://datavaultalliance.com/about/what-is-datavault/ Kimball: https://www.astera.com/type/blog/data-warehouse-concepts/#The-Kimball-Method Inmon: https://www.astera.com/type/blog/data-warehouse-concepts/#The-Inmon-Method  üîπdbt If you are in the data space I definitely recommend to learn dbt, as it helps you to create reliable and reproducable data transformations\n dbt: https://www.getdbt.com/  üîπApache Spark Apache Spark is the most effective data processing framework in enterprises today. Almost all companies that I encountered that have big data projects use Spark in one way or the other. While Apache Sparks ‚Äúnative‚Äù language is Scala it works with python too. Performance is a bit less, but it integrates a lot easier with the rest of your data pipeline projects through using the same language. Spark is also capable of running SQL commands, which is pretty cool as well.\n PySpark: https://intellipaat.com/blog/tutorial/spark-tutorial/pyspark-tutorial/ Learn Spark: https://sparkbyexamples.com/  üîπDatabricks \u0026 Delta Databricks combines the best of the DWH with the Data lake world. One of the big advantages in my eyes is that you can handle multiple types of data like unstructured and structured data in one plattform which makes overhead a lot smaller.\n Read more: https://databricks.com/  üîπApache Kafka If you need to work with data streaming I recommend to look at Apache Kafka. If you are using Azure Cloud you can also use Azure Event Hub, as it also offers support for Kafka Consumer and Producer API.\n What, when and why to use Kafka: https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/ Getting Started: https://kafka.apache.org/quickstart .NET and Kafka: https://github.com/kunwarshesh/Start-with-Kafka-DotNetCore  What other technical skills are needed as a data engineer? Please let me know in the comments üì©\n","wordCount":"791","inLanguage":"en","datePublished":"2022-02-04T22:42:14+01:00","dateModified":"2022-02-04T22:42:14+01:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ninomueller.com/posts/data-engineering-skills-2022/"},"publisher":{"@type":"Organization","name":"Nino M√ºller Dataverse","logo":{"@type":"ImageObject","url":"https://ninomueller.com/favicon.ico"}}}</script>
</head>
<body id=top>
<script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script>
<header class=header>
<nav class=nav>
<div class=logo>
<a href=https://ninomueller.com accesskey=h title="Nino M√ºller Dataverse (Alt + H)">Nino M√ºller Dataverse</a>
<span class=logo-switches>
<button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg>
</button>
</span>
</div>
<ul id=menu>
</ul>
</nav>
</header>
<main class=main>
<article class=post-single>
<header class=post-header>
<h1 class=post-title>
Data Engineering Skills 2022
</h1>
<div class=post-meta><span title="2022-02-04 22:42:14 +0100 +0100">February 4, 2022</span>
</div>
</header>
<div class=post-content><p>One of my tasks at Substring is to always scout for technology trends to find out what technologies help our clients most to reach their target to become Data-driven. The tech field for fats engineers is huge and evolving fast.</p>
<p>I put together a short list of tech skills that I think data engineers in 2022 should master to give as much value to clients as possible. Obviously there is a load of so called soft skills needed as well. Maybe I will do a post about them as well in the future.</p>
<p>üîπProgramming / Coding
In the end a data engineer is a highly specialized software engineer. So learn the most important languages to interact with data and data pipelines. If you know python, bash and SQL you will get far already. If you ever encounter someone that tells you SQL is an old language or that it&rsquo;s not useful anymore, just laugh and walk away ü§£</p>
<p>Some important tools like Spark rely heavily on Java and Scala so it can be important that you know this too.</p>
<ul>
<li>Basics SQL: <a href=https://www.dataquest.io/blog/sql-basics/>https://www.dataquest.io/blog/sql-basics/</a></li>
<li>Basics Python: <a href=https://www.python.org/about/gettingstarted/>https://www.python.org/about/gettingstarted/</a></li>
</ul>
<p>üîπSQL databases
Many systems rely on some sort of SQL based database. Invest some time in SQL based systems like Postgres, Azure SQL, Snowflake others.</p>
<p>Many developers believe that nowadays everything is about NoSQL because &ldquo;it&rsquo;s more scalable&rdquo; or &ldquo;it&rsquo;s the way to go with big data&rdquo;. While this might be true, it is also quite difficult to handle transactions and consistency in data with systems like this. Not everything that starts cheaper and faster in the beginning stays like that in the long run. ü§î Most OLTP systems and transactional data systems should and will still use an RDBMS system, so prepare for this.</p>
<p>üîπCloud & Kubernetes
Learn the basics about K8s as you will need to use it a lot to run data pipelines. If you are a beginner just tinker aroune with minikube on your local computer. Later decide to learn about how to work with one of the big cloud providers AWS, Azure and GCP. I personally prefer Azure because they have a great integration of tools like Apache Databricks, MLFlow and other stuff that I need regularly.</p>
<p>In the end I would choose based on who your target clients are. Swiss SMEs work with Azure, because they are used to work with Microsoft and trust in Google and Amazon is lower. Startups use AWS because it is a bit cheaper for smaller workloads.</p>
<ul>
<li>Learn Kubernetes: <a href=https://kubernetes.io/docs/tutorials/kubernetes-basics/>https://kubernetes.io/docs/tutorials/kubernetes-basics/</a></li>
</ul>
<p>üîπNoSQL
If you get into the big data field, it&rsquo;s necessary to learn about NoSQL databases. Now, there are multiple types of NoSQL databases, some of them are highly available and some of them are highly consistent. Some are column-based, some are document-based and some are graph-based.</p>
<p>I recommend to try and learn about a couple of them:</p>
<ul>
<li>MongoDB (<a href=https://www.mongodb.com/>https://www.mongodb.com/</a>)</li>
<li>Cassandra (<a href=https://cassandra.apache.org/_/index.html>https://cassandra.apache.org/_/index.html</a>)</li>
<li>ElasticSearch (<a href=https://www.elastic.co/>https://www.elastic.co/</a>)</li>
<li>Azure Cosmos DB (<a href=https://azure.microsoft.com/en-us/services/cosmos-db/#overview>https://azure.microsoft.com/en-us/services/cosmos-db/#overview</a>)</li>
<li>neo4j (<a href=https://neo4j.com/>https://neo4j.com/</a>)</li>
</ul>
<p>Just run them locally on your docker and tinker around. You can find a couple of docker files for them here <a href=https://github.com/irbigdata/data-dockerfiles>https://github.com/irbigdata/data-dockerfiles</a></p>
<p>üîπData Warehousing
Learn about data warehouses and how to store data in them and systems of storing data like Kimball, Data Vault 2.0 or others. Learn about slowly changing dimensions, ELT, ETL and other concepts around DWHs.</p>
<ul>
<li>Data Vault 2.0: <a href=https://datavaultalliance.com/about/what-is-datavault/>https://datavaultalliance.com/about/what-is-datavault/</a></li>
<li>Kimball: <a href=https://www.astera.com/type/blog/data-warehouse-concepts/#The-Kimball-Method>https://www.astera.com/type/blog/data-warehouse-concepts/#The-Kimball-Method</a></li>
<li>Inmon: <a href=https://www.astera.com/type/blog/data-warehouse-concepts/#The-Inmon-Method>https://www.astera.com/type/blog/data-warehouse-concepts/#The-Inmon-Method</a></li>
</ul>
<p>üîπdbt
If you are in the data space I definitely recommend to learn dbt, as it helps you to create reliable and reproducable data transformations</p>
<ul>
<li>dbt: <a href=https://www.getdbt.com/>https://www.getdbt.com/</a></li>
</ul>
<p>üîπApache Spark
Apache Spark is the most effective data processing framework in enterprises today. Almost all companies that I encountered that have big data projects use Spark in one way or the other.
While Apache Sparks &ldquo;native&rdquo; language is Scala it works with python too. Performance is a bit less, but it integrates a lot easier with the rest of your data pipeline projects through using the same language. Spark is also capable of running SQL commands, which is pretty cool as well.</p>
<ul>
<li>PySpark: <a href=https://intellipaat.com/blog/tutorial/spark-tutorial/pyspark-tutorial/>https://intellipaat.com/blog/tutorial/spark-tutorial/pyspark-tutorial/</a></li>
<li>Learn Spark: <a href=https://sparkbyexamples.com/>https://sparkbyexamples.com/</a></li>
</ul>
<p>üîπDatabricks & Delta
Databricks combines the best of the DWH with the Data lake world. One of the big advantages in my eyes is that you can handle multiple types of data like unstructured and structured data in one plattform which makes overhead a lot smaller.</p>
<ul>
<li>Read more: <a href=https://databricks.com/>https://databricks.com/</a></li>
</ul>
<p>üîπApache Kafka
If you need to work with data streaming I recommend to look at Apache Kafka. If you are using Azure Cloud you can also use Azure Event Hub, as it also offers support for Kafka Consumer and Producer API.</p>
<ul>
<li>What, when and why to use Kafka: <a href=https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/>https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/</a></li>
<li>Getting Started: <a href=https://kafka.apache.org/quickstart>https://kafka.apache.org/quickstart</a></li>
<li>.NET and Kafka: <a href=https://github.com/kunwarshesh/Start-with-Kafka-DotNetCore>https://github.com/kunwarshesh/Start-with-Kafka-DotNetCore</a></li>
</ul>
<p>What other technical skills are needed as a data engineer? Please let me know in the comments üì©</p>
</div>
<footer class=post-footer>
</footer><div id=disqus_thread></div>
<script>var disqus_config=function(){this.page.url="https://ninomueller.com/posts/data-engineering-skills-2022/",this.page.identifier='nino-muller'};(function(){var a=document,b=a.createElement('script');b.src='https://nino-muller.disqus.com/embed.js',b.setAttribute('data-timestamp',+new Date),(a.head||a.body).appendChild(b)})()</script>
<noscript>Please enable JavaScript to view the
<a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript>
</article>
</main>
<footer class=footer>
<span>&copy; 2022 <a href=https://ninomueller.com>Nino M√ºller Dataverse</a></span>
<span>
Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a>
</span>
</footer>
<a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a>
<script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script>
<script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script>
<script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script>
</body>
</html>